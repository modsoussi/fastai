{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastbook import untar_data, URLs, Learner, MSELossFlat\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.ML_100k)\n",
    "\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(path/'u.data', delimiter='\\t', header=None, names=['user', 'movie', 'rating', 'timestamp'])\n",
    "\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(path/'u.item', delimiter='|', header=None, names=['movie', 'title'], encoding='latin-1', usecols=(0,1))\n",
    "\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.merge(movies)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[movies['title'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollabBase(torch.nn.Module):\n",
    "  def __init__(self, n_users, n_items, n_factors=50) -> None:\n",
    "    super().__init__()\n",
    "    \n",
    "    self.user_embs = torch.nn.Embedding(n_users, n_factors)\n",
    "    self.item_embs = torch.nn.Embedding(n_items, n_factors)\n",
    "    \n",
    "  def forward(self, x) -> None:\n",
    "    users = self.user_embs(x[:, 0])\n",
    "    items = self.item_embs(x[:, 1])\n",
    "    \n",
    "    return (users*items).sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = ratings['user'].unique().size + 1\n",
    "n_movies = movies['movie'].unique().size + 1\n",
    "\n",
    "n_users, n_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab_base_model = CollabBase(n_users, n_movies, n_factors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.tensor(ratings[['user','movie']].to_numpy())\n",
    "train_y = torch.tensor(ratings['rating'].to_numpy(), dtype=torch.float32).reshape(100000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = collab_base_model(train_x)\n",
    "\n",
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(preds: torch.torch.torch.Tensor, acts: torch.Tensor):\n",
    "  return ((preds-acts)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(preds, train_y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in collab_base_model.parameters():\n",
    "  print(p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_norm(model: torch.nn.Module):\n",
    "  total_norm = 0\n",
    "  for p in model.parameters():\n",
    "    p_norm = p.grad.data.norm(2)\n",
    "    total_norm += p_norm.item()**2\n",
    "\n",
    "  return total_norm**(1./2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = calculate_norm(collab_base_model)\n",
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = train_x[:64]\n",
    "batch_y = train_y[:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = collab_base_model(batch_x)\n",
    "loss = loss_fn(preds, batch_y)\n",
    "\n",
    "for p in collab_base_model.parameters():\n",
    "  p.grad.zero_()\n",
    "  \n",
    "loss.backward()\n",
    "\n",
    "total_norm = calculate_norm(collab_base_model)\n",
    "total_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in collab_base_model.parameters():\n",
    "  print(p.grad.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "def train(model: torch.nn.Module, train_x: torch.Tensor, train_y: torch.Tensor, n_epochs=5, lr=.1, loss_fn=F.mse_loss, wd=0.0): \n",
    "  if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    model.to('mps')\n",
    "    x = train_x.to('mps')\n",
    "    y = train_y.to('mps')\n",
    "  \n",
    "  dataset = data.TensorDataset(x,y)\n",
    "  \n",
    "  train_size = round(.8 * len(x))\n",
    "  valid_size = len(x) - train_size\n",
    "  train_set, validation_set = data.random_split(dataset, [train_size, valid_size])\n",
    "  \n",
    "  t_loader = data.DataLoader(train_set, 64, True)\n",
    "  v_loader = data.DataLoader(validation_set, 64, True)\n",
    "  \n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=wd)\n",
    "  for i in range(n_epochs):\n",
    "    model.train()\n",
    "    t_loss = 0.0\n",
    "    for xb, yb in t_loader:\n",
    "      optimizer.zero_grad()\n",
    "      preds = model(xb)\n",
    "      loss = loss_fn(preds, yb)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      t_loss += loss.item()\n",
    "    \n",
    "    t_loss /= len(t_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    v_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "      for vbx, vby in v_loader:\n",
    "        preds = model(vbx)\n",
    "        loss = loss_fn(preds, vby)\n",
    "        v_loss += loss.item()\n",
    "      \n",
    "    v_loss /= len(v_loader)\n",
    "    \n",
    "    print(f\"t_loss: {t_loss} - v_loss: {v_loss}\")\n",
    "    \n",
    "  model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = CollabBase(n_users, n_movies, n_factors=50)\n",
    "\n",
    "train(test_model, train_x, train_y, lr=5e-2, loss_fn=F.mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollabBaseWithSigmoid(torch.nn.Module):\n",
    "  def __init__(self, n_users, n_items, n_factors=50, y_range=(0, 5.5)) -> None:\n",
    "    super().__init__()\n",
    "    \n",
    "    self.user_embs = torch.nn.Parameter(torch.zeros((n_users, n_factors)).normal_(0, .1))\n",
    "    self.item_embs = torch.nn.Parameter(torch.zeros((n_items, n_factors)).normal_(0, .1))\n",
    "    self.y_range = y_range\n",
    "    \n",
    "  def forward(self, x):\n",
    "    users = self.user_embs[x[:,0]]\n",
    "    items = self.item_embs[x[:, 1]]\n",
    "    \n",
    "    return F.sigmoid((users*items).sum(dim=1, keepdim=True))*(self.y_range[1]-self.y_range[0])+self.y_range[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = CollabBaseWithSigmoid(n_users, n_movies)\n",
    "\n",
    "# train(test_model, train_x=train_x, train_y=train_y, lr=.1)\n",
    "preds = test_model(train_x)\n",
    "loss = F.mse_loss(preds, train_y)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in test_model.parameters():\n",
    "  print(p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = CollabBaseWithSigmoid(n_users, n_movies)\n",
    "\n",
    "train(test_model, train_x=train_x, train_y=train_y, lr=5e-1, loss_fn=F.mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollabWithBias(torch.nn.Module):\n",
    "  def __init__(self, n_users, n_items, n_factors=50, y_range=(0,5.5)) -> None:\n",
    "    super().__init__()\n",
    "    \n",
    "    self.user_embs = torch.nn.Embedding(n_users, n_factors)\n",
    "    torch.nn.init.normal_(self.user_embs.weight, 0, .1)\n",
    "    self.user_bias = torch.nn.Embedding(n_users, 1)\n",
    "    \n",
    "    self.item_embs = torch.nn.Embedding(n_items, n_factors)\n",
    "    torch.nn.init.normal_(self.item_embs.weight, 0, .1)\n",
    "    self.item_bias = torch.nn.Embedding(n_items, 1)\n",
    "    \n",
    "    self.y_range = y_range\n",
    "    \n",
    "  def forward(self, x) -> torch.Tensor:\n",
    "    users = self.user_embs(x[:, 0])\n",
    "    user_bias = self.user_bias(x[:, 0])\n",
    "    \n",
    "    items = self.item_embs(x[:, 1])\n",
    "    item_bias = self.item_bias(x[:, 1])\n",
    "    \n",
    "    interaction = (users * items).sum(dim=1, keepdim=True)\n",
    "    interaction += user_bias + item_bias\n",
    "    \n",
    "    return F.sigmoid(interaction)*(self.y_range[1]-self.y_range[0]) + self.y_range[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = CollabWithBias(n_users, n_movies)\n",
    "\n",
    "train(test_model, train_x=train_x, train_y=train_y, loss_fn=F.mse_loss, lr=5e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_bias = test_model.item_bias.weight.squeeze()\n",
    "movie_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = movie_bias.argsort()[:5].tolist()\n",
    "\n",
    "[movies['title'][i-1] for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(train_x[:5]), train_y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  print(F.mse_loss(test_model(train_x[:10]), train_y[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = CollabWithBias(n_users, n_movies)\n",
    "\n",
    "train(test_model, train_x=train_x, train_y=train_y, loss_fn=F.mse_loss, lr=8e-1, n_epochs=5, wd=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(train_x[:5]), train_y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
