{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from fastbook import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='15687680' class='' max='15683414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.03% [15687680/15683414 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('training'),Path('testing')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [Path('training/7'),Path('training/8'),Path('training/5'),Path('training/6'),Path('training/9'),Path('training/3'),Path('training/2'),Path('training/0'),Path('training/4'),Path('training/1')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'training').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "for i in range(10):\n",
    "  xs.append(torch.stack([tensor(Image.open(o)) \n",
    "                          for o in (path/'training'/f'{i}').ls() ]).float()/255)\n",
    "  ys += [i]*len((path/'training'/f'{i}').ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = torch.cat(xs).view(-1, 28*28)\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = tensor(ys)\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.):\n",
    "  return (torch.randn(size)*std).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = init_params((28*28, 10))\n",
    "b = init_params(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x): return x@w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -1.1250, -14.8991,   5.2417,  -0.3008,   5.7340,  -7.2487,   8.3564,   4.6382,   3.9403, -13.6559],\n",
       "        [ -8.1837,  -5.0914,  -2.2739,  -7.2089,  19.4128,   5.7646,   8.5149,   3.0100,   2.0764,   1.3862],\n",
       "        [  8.0232,  -1.4075, -17.4992,  -9.3129,  28.8827,   2.7493,   5.6040,  16.0178,  -3.5600,  -7.9606],\n",
       "        [  9.1720,  -8.8000,  -4.8951, -28.3459,   7.3776, -23.0282,  15.8965,   8.2482,  11.3917, -13.2118],\n",
       "        [  4.9161,  -9.0179,   8.1191,  -5.5356,   9.3036,  -8.7133,  13.4189,  11.0129,  -4.3309, -16.2302]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acts = linear(train_x[:5])\n",
    "acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[6.6103e-05, 6.8892e-11, 3.8481e-02, 1.5071e-04, 6.2957e-02, 1.4478e-07, 8.6683e-01, 2.1045e-02, 1.0473e-02, 2.3883e-10],\n",
       "         [1.0351e-12, 2.2801e-11, 3.8156e-10, 2.7436e-12, 9.9998e-01, 1.1820e-06, 1.8497e-05, 7.5221e-08, 2.9571e-08, 1.4829e-08],\n",
       "         [8.7263e-10, 7.0011e-14, 7.1880e-21, 2.5816e-17, 1.0000e+00, 4.4713e-12, 7.7659e-11, 2.5873e-06, 8.1341e-15, 9.9810e-17],\n",
       "         [1.1858e-03, 1.8574e-11, 9.2202e-10, 6.0282e-20, 1.9711e-04, 1.2293e-17, 9.8723e-01, 4.7077e-04, 1.0915e-02, 2.2536e-13],\n",
       "         [1.8250e-04, 1.6211e-10, 4.4910e-03, 5.2742e-09, 1.4681e-02, 2.1985e-10, 8.9953e-01, 8.1117e-02, 1.7594e-08, 1.1956e-13]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_acts = acts.softmax(1)\n",
    "yt = train_y[:5]\n",
    "sm_acts, yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>))"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sm_acts), sm_acts.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.6103e-05, 1.0351e-12, 8.7263e-10, 1.1858e-03, 1.8250e-04], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_acts[range(5),yt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(preds):\n",
    "  return torch.log(preds.softmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.6243, 27.5966, 20.8595,  6.7373,  8.6087], grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-log_softmax(linear(train_x[:5]))[range(5), train_y[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.6853, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.nll_loss(torch.log(linear(train_x[:5]).softmax(1)), train_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.6853, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(linear(train_x[:5]), train_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.6853, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.CrossEntropyLoss()(linear(train_x[:5]), train_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(preds, acts):\n",
    "  idx = range(len(acts))\n",
    "  return -log_softmax(preds)[idx, acts].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.6853, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_loss(linear(train_x[:5]), train_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = list(zip(train_x, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsetl = DataLoader(dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_step(x, y, model):\n",
    "  preds = model(x)\n",
    "  loss = mnist_loss(preds, y)\n",
    "  loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(preds, y):\n",
    "  preds = preds.softmax(1)[range(len(y)), y]\n",
    "  correct = (preds > 0.95)\n",
    "  return correct.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_accuracy(linear(train_x[:5]), train_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optim:\n",
    "  def __init__(self, params, lr) -> None:\n",
    "    self.params, self.lr = list(params), lr\n",
    "  \n",
    "  def step(self):\n",
    "    for p in self.params:\n",
    "      p.data -= p.grad.data * self.lr\n",
    "  \n",
    "  def zero(self):\n",
    "    for p in self.params:\n",
    "      p.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dls, model, opt, num_epochs=5):\n",
    "  for i in range(num_epochs):\n",
    "    for xb, yb in dls:\n",
    "      gradient_step(xb, yb, model)\n",
    "      opt.step()\n",
    "      opt.zero()\n",
    "    \n",
    "    print(batch_accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9271)\n",
      "tensor(0.9375)\n",
      "tensor(0.9375)\n",
      "tensor(0.9271)\n",
      "tensor(0.9271)\n",
      "tensor(0.9479)\n",
      "tensor(0.9479)\n",
      "tensor(0.9479)\n",
      "tensor(0.9479)\n",
      "tensor(0.9479)\n",
      "tensor(0.9479)\n",
      "tensor(0.9479)\n",
      "tensor(0.9479)\n",
      "tensor(0.9479)\n",
      "tensor(0.9479)\n",
      "tensor(0.9479)\n",
      "tensor(0.9479)\n",
      "tensor(0.9479)\n",
      "tensor(0.9375)\n",
      "tensor(0.9271)\n"
     ]
    }
   ],
   "source": [
    "params = w,b\n",
    "opt = Optim(params, 0.1)\n",
    "\n",
    "train(dsetl, linear, opt, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9999, 1.0000, 1.0000, 0.2881, 1.0000], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(train_x[:5]).softmax(1)[range(5), train_y[:5]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABCUlEQVR4nM3PoUtDURTH8e8T4eFgSdCgi2srahGDMBCDJv0DTIJah8FiEdOCSzbBYnBpoiwJgsLQotFimiAT0wTZEH/nXcvVwbsvGjzldzmfy4Ef/LOJBs/x2fnl4tFHs/UZ/IpX32SSTIdxgAXJo7YDvBhgdyZlFWe1amL2/mJmFb8c8rmUuNKWc26veOucS+E9lEeAeu9gcO4H99eeAFY6dLIaL5p97QI7ZmdpG21LbSC+lO5SZ8lNwCkwVoZ6GgFefT74HP6VCCLINyJq1wE6cNCYcjTTVfxszsFVK2hSkPRc7cm0ENbM35glZpb0p0Ok1JVJ6m9kGBzLpMf1TCN3bjqZzLY/nW9x6X3B9N/oEwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = (path/'training'/'0').ls()[3]\n",
    "img = Image.open(img_path)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xs = []\n",
    "test_ys = []\n",
    "for i in range(10):\n",
    "  test_xs.append(torch.stack([tensor(Image.open(o)) \n",
    "                          for o in (path/'testing'/f'{i}').ls() ]).float()/255)\n",
    "  test_ys += [i]*len((path/'testing'/f'{i}').ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = torch.cat(test_xs).view(-1, 28*28)\n",
    "test_y = torch.tensor(test_ys)\n",
    "test_dset = list(zip(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dset_loader = DataLoader(test_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5245)"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_accuracy(linear(test_x), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9439, 0.9997, 1.0000, 0.9989, 0.2996], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(test_x[:5]).softmax(1)[range(5), test_y[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9klEQVR4nGNgGFggdf/fqQYccpGb/v79+22RDja50vt/T/dWBTw57Ygpp/T+31peBgYG2dlvbdHlFG7/beBgYGBgYGCf/9kUTbL13xY4e95XYxQ5zqN/xRG8f4Uokv5/d7EheF13hJElF/11QuLx38lnYGBgYGCC8h9eR5L8eMwTWZLx9nNkgxjVJZEk//9HccI2OVFkY1HBNwYUOyUFkSWDUSV1ZFG0PnyNxBE7d4UXwUv6txNFqeXXVWIwtva/r0mobrA8e3OJMAMDA4Nxwff/1eguFL3y986FCxcvfPz7d7oguiQDb+LKv3///f17OQxDio4AABOJUWfKm6/MAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = (path/'testing'/'0').ls()[4]\n",
    "img = Image.open(img_path)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net = torch.nn.Sequential(\n",
    "  torch.nn.Linear(28*28, 450),\n",
    "  torch.nn.ReLU(),\n",
    "  torch.nn.Linear(450, 10),\n",
    "  torch.nn.Softmax(dim=-1)\n",
    ")\n",
    "\n",
    "def nn_batch_accuracy(preds, acts):\n",
    "  idx = range(len(acts))\n",
    "  correct = (preds[idx, acts] > 0.95)\n",
    "  return correct.float().mean()\n",
    "\n",
    "learner = Learner(DataLoaders(dsetl, test_dset_loader), neural_net, \n",
    "                  loss_func=torch.nn.CrossEntropyLoss(), opt_func=SGD,\n",
    "                  metrics=nn_batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>nn_batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.251955</td>\n",
       "      <td>2.302238</td>\n",
       "      <td>0.027750</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.063459</td>\n",
       "      <td>2.249845</td>\n",
       "      <td>0.084183</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.954836</td>\n",
       "      <td>2.152755</td>\n",
       "      <td>0.095933</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.888305</td>\n",
       "      <td>2.091505</td>\n",
       "      <td>0.127650</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.855887</td>\n",
       "      <td>2.053017</td>\n",
       "      <td>0.166583</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.838477</td>\n",
       "      <td>2.027930</td>\n",
       "      <td>0.212450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.827112</td>\n",
       "      <td>2.010139</td>\n",
       "      <td>0.249200</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.812435</td>\n",
       "      <td>1.992324</td>\n",
       "      <td>0.280583</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.806601</td>\n",
       "      <td>1.973650</td>\n",
       "      <td>0.314167</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.801617</td>\n",
       "      <td>1.955815</td>\n",
       "      <td>0.339667</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.765957</td>\n",
       "      <td>1.944161</td>\n",
       "      <td>0.257000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.637821</td>\n",
       "      <td>1.958646</td>\n",
       "      <td>0.233183</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.624161</td>\n",
       "      <td>1.945172</td>\n",
       "      <td>0.255333</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.617273</td>\n",
       "      <td>1.931875</td>\n",
       "      <td>0.274617</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.611914</td>\n",
       "      <td>1.920374</td>\n",
       "      <td>0.289167</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.603643</td>\n",
       "      <td>1.918952</td>\n",
       "      <td>0.291267</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.583961</td>\n",
       "      <td>1.909009</td>\n",
       "      <td>0.302350</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.578048</td>\n",
       "      <td>1.898295</td>\n",
       "      <td>0.314483</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.574790</td>\n",
       "      <td>1.889111</td>\n",
       "      <td>0.326650</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.572286</td>\n",
       "      <td>1.880971</td>\n",
       "      <td>0.337383</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit(20, 8e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstart_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m Fit `self.model` for `n_epoch` using `cbs`. Optionally `reset_opt`.\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "    \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mstart_epoch\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mSkipToEpoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madded_cbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mreset_opt\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mwd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mwd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/opt/anaconda3/envs/fastai/lib/python3.9/site-packages/fastai/learner.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "learner.fit??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.088885</td>\n",
       "      <td>0.043944</td>\n",
       "      <td>0.011917</td>\n",
       "      <td>07:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits = DataBlock(\n",
    "  blocks=(ImageBlock, CategoryBlock),\n",
    "  get_items=get_image_files,\n",
    "  splitter=RandomSplitter(seed=42),\n",
    "  get_y=parent_label,\n",
    ")\n",
    "learner = vision_learner(digits.dataloaders(path/'training'), \n",
    "                         resnet18, metrics=error_rate)\n",
    "learner.fine_tune(1, base_lr=.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3223c46f09d6cc08fb5d72081db0e4c926122c7ca4f0e6758ead674d5ecbab6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
